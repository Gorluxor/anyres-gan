{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HTML\n",
    "from ipyevents import Event \n",
    "from IPython.display import display\n",
    "import torch\n",
    "import pickle\n",
    "from util import renormalize, viz_util, patch_util\n",
    "import numpy as np\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'pretrained/bird_pretrained_final.pkl'\n",
    "# pretrained_path = 'pretrained/church_pretrained_final.pkl'\n",
    "# pretrained_path = 'pretrained/ffhq6k_pretrained_final.pkl'\n",
    "# pretrained_path = 'pretrained/mountain_pretrained_final.pkl'\n",
    "\n",
    "with open(pretrained_path, 'rb') as f:\n",
    "    G_base = pickle.load(f)['G_ema'].cuda()  # torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-wallace",
   "metadata": {},
   "source": [
    "# interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(19)\n",
    "z = torch.from_numpy(rng.standard_normal(G_base.z_dim)).float()\n",
    "z = z[None].cuda()\n",
    "c = None\n",
    "ws = G_base.mapping(z, c, truncation_psi=0.5, truncation_cutoff=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'patch_size': G_base.img_resolution,\n",
    "    'display_size': min(400, G_base.img_resolution),\n",
    "    'shift_rate': 10,\n",
    "    'zoom_rate': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = patch_util.scale_condition_wrapper(G_base, ws, transform=None, noise_mode='const', force_fp32=True)\n",
    "bbox_info = viz_util.init_bbox(params)\n",
    "\n",
    "# get initial transformation\n",
    "base_img = img[0]\n",
    "generated_img, display_img = viz_util.update_img(bbox_info, True, True, None, None, params, G_base, ws)\n",
    "transform = viz_util.bbox_to_transformation(bbox_info)[None].to(ws.device)\n",
    "\n",
    "img_url = renormalize.as_url(viz_util.draw_bbox(bbox_info, base_img), source='pil', size=params['display_size'])\n",
    "patch_url = renormalize.as_url(display_img, size=params['display_size'])\n",
    "img_html = '<div class=\"row\"> <img src=\"%s\"/> <img src=\"%s\"/> </div>' % (img_url, patch_url)\n",
    "l = HTML(img_html)\n",
    "\n",
    "text = HTML('Use arrow keys to pan, i to zoom in, o to zoom out, and c to reset.')\n",
    "h = HTML('Full size: %d' % bbox_info['full_size'])\n",
    "d = Event(source=l, watched_events=['keydown'])\n",
    "\n",
    "def handle_event(event):\n",
    "    global bbox_info\n",
    "    global display_img\n",
    "    global generated_img\n",
    "    bbox_info, generated_img, display_img = viz_util.update_bbox(\n",
    "        event['key'], bbox_info, generated_img, display_img, G_base, ws, params)\n",
    "    img_url =  renormalize.as_url(viz_util.draw_bbox(bbox_info, base_img), source='pil', size=params['display_size'])\n",
    "    patch_url = renormalize.as_url(display_img, size=params['display_size'])\n",
    "    img_html = '<div class=\"row\"> <img src=\"%s\"/> <img src=\"%s\"/> </div>' % (img_url, patch_url)\n",
    "    l.value = img_html\n",
    "    content = 'Full size: %d' % bbox_info['full_size']\n",
    "    h.value = content\n",
    "\n",
    "d.on_dom_event(handle_event)\n",
    "display(text, h, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-carpet",
   "metadata": {},
   "source": [
    "# generate full image from patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(19)\n",
    "z = torch.from_numpy(rng.standard_normal(G_base.z_dim)).float()\n",
    "z = z[None].cuda()\n",
    "c = None\n",
    "ws = G_base.mapping(z, c, truncation_psi=0.5, truncation_cutoff=8)\n",
    "img = patch_util.scale_condition_wrapper(G_base, ws, transform=None, noise_mode='const', force_fp32=True)\n",
    "renormalize.as_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_size = 1024\n",
    "full = torch.zeros([1, 3, full_size, full_size])\n",
    "patches = patch_util.generate_full_from_patches(full_size, G_base.img_resolution)\n",
    "for bbox, transform in patches:\n",
    "    img = patch_util.scale_condition_wrapper(G_base, ws, transform[None].cuda(), noise_mode='const', force_fp32=True)\n",
    "    full[:, :, bbox[0]:bbox[1], bbox[2]:bbox[3]] = img\n",
    "renormalize.as_image(full[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-palmer",
   "metadata": {},
   "source": [
    "# panorama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'pretrained/mountain_pano_pretrained_final.pkl'\n",
    "with open(pretrained_path, 'rb') as f:\n",
    "    G_pano = pickle.load(f)['G_ema'].cuda()  # torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(10)\n",
    "z = torch.from_numpy(rng.standard_normal(G_pano.z_dim)).float()\n",
    "z = z[None].cuda()\n",
    "c = None\n",
    "\n",
    "input_layer = G_pano.synthesis.input\n",
    "grid = viz_util.make_grid(G_pano)\n",
    "start_shift = np.random.randint(360 / input_layer.fov * input_layer.frame_size[0])\n",
    "start_grid = grid[:, :, start_shift:start_shift+input_layer.size[0], :]\n",
    "pano = viz_util.generate_pano_transform(G_pano, z, start_grid)\n",
    "renormalize.as_image(pano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splice the start and end of the pano together --> seamless image\n",
    "pano_width = pano.shape[-1]\n",
    "renormalize.as_image(torch.cat([pano, pano], dim=2)[:, :, pano_width-2*G_pano.img_resolution:pano_width+2*G_pano.img_resolution])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anyres-gan",
   "language": "python",
   "name": "anyres-gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
