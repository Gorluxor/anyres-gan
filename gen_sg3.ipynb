{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import click\n",
    "import dnnlib\n",
    "import os\n",
    "import PIL.Image\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from gen_images import parse_range, parse_vec2, make_transform\n",
    "import legacy\n",
    "def generate_images(\n",
    "    network_pkl: str,\n",
    "    seeds: List[int],\n",
    "    truncation_psi: float,\n",
    "    noise_mode: str,\n",
    "    outdir: str,\n",
    "    translate: Tuple[float,float],\n",
    "    rotate: float,\n",
    "    class_idx: Optional[int]\n",
    "):\n",
    "    \"\"\"Generate images using pretrained network pickle.\n",
    "    Examples:\n",
    "    \\b\n",
    "    # Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n",
    "    python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n",
    "        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n",
    "    \\b\n",
    "    # Generate uncurated images with truncation using the MetFaces-U dataset\n",
    "    python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n",
    "        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n",
    "    \"\"\"\n",
    "\n",
    "    print('Loading networks from \"%s\"...' % network_pkl)\n",
    "    device = torch.device('cuda')\n",
    "    with dnnlib.util.open_url(network_pkl) as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
    "        #G = legacy.load_network_pkl(f)['G'].to(device) # type: ignore\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # Labels.\n",
    "    label = torch.zeros([1, G.c_dim], device=device)\n",
    "    if G.c_dim != 0:\n",
    "        if class_idx is None:\n",
    "            raise click.ClickException('Must specify class label with --class when using a conditional network')\n",
    "        label[:, class_idx] = 1\n",
    "    else:\n",
    "        if class_idx is not None:\n",
    "            print ('warn: --class=lbl ignored when running on an unconditional network')\n",
    "\n",
    "    # Generate images.\n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n",
    "        z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device)\n",
    "\n",
    "        # Construct an inverse rotation/translation matrix and pass to the generator.  The\n",
    "        # generator expects this matrix as an inverse to avoid potentially failing numerical\n",
    "        # operations in the network.\n",
    "        if hasattr(G.synthesis, 'input'):\n",
    "            m = make_transform(translate, rotate)\n",
    "            #print(m)\n",
    "            m = np.linalg.inv(m)\n",
    "            #print(m)\n",
    "            G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
    "\n",
    "        img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
    "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load cudnn\n",
    "generate_images(\"pretrained/stylegan3-t-ffhq-1024x1024.pkl\", list(range(19, 19+16)), 0.5, \"const\", \"out2\", (0,0), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_pkl = \"pretrained/stylegan3-t-ffhq-1024x1024.pkl\"\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)# ['G_ema'].to(device) # type: ignore\n",
    "G_b = G['G_ema'].to(device)\n",
    "seed = 19\n",
    "z = torch.from_numpy(np.random.RandomState(seed).randn(1, G_b.z_dim)).to(device)\n",
    "label = torch.zeros([1, G_b.c_dim], device=device)\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Generator                                     [1, 3, 1024, 1024]        --\n",
       "├─MappingNetwork: 1-1                         [1, 16, 512]              --\n",
       "│    └─FullyConnectedLayer: 2-1               [1, 512]                  (262,656)\n",
       "│    └─FullyConnectedLayer: 2-2               [1, 512]                  (262,656)\n",
       "├─SynthesisNetwork: 1-2                       [1, 3, 1024, 1024]        --\n",
       "│    └─SynthesisInput: 2-3                    [1, 512, 36, 36]          262,144\n",
       "│    │    └─FullyConnectedLayer: 3-1          [1, 4]                    (2,052)\n",
       "│    └─SynthesisLayer: 2-4                    [1, 512, 36, 36]          2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-2          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-5                    [1, 512, 36, 36]          2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-3          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-6                    [1, 512, 52, 52]          2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-4          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-7                    [1, 512, 52, 52]          2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-5          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-8                    [1, 512, 84, 84]          2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-6          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-9                    [1, 512, 148, 148]        2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-7          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-10                   [1, 512, 148, 148]        2,359,808\n",
       "│    │    └─FullyConnectedLayer: 3-8          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-11                   [1, 323, 276, 276]        1,488,707\n",
       "│    │    └─FullyConnectedLayer: 3-9          [1, 512]                  (262,656)\n",
       "│    └─SynthesisLayer: 2-12                   [1, 203, 276, 276]        590,324\n",
       "│    │    └─FullyConnectedLayer: 3-10         [1, 323]                  (165,699)\n",
       "│    └─SynthesisLayer: 2-13                   [1, 128, 532, 532]        233,984\n",
       "│    │    └─FullyConnectedLayer: 3-11         [1, 203]                  (104,139)\n",
       "│    └─SynthesisLayer: 2-14                   [1, 81, 1044, 1044]       93,393\n",
       "│    │    └─FullyConnectedLayer: 3-12         [1, 128]                  (65,664)\n",
       "│    └─SynthesisLayer: 2-15                   [1, 51, 1044, 1044]       37,230\n",
       "│    │    └─FullyConnectedLayer: 3-13         [1, 81]                   (41,553)\n",
       "│    └─SynthesisLayer: 2-16                   [1, 32, 1044, 1044]       14,720\n",
       "│    │    └─FullyConnectedLayer: 3-14         [1, 51]                   (26,163)\n",
       "│    └─SynthesisLayer: 2-17                   [1, 32, 1024, 1024]       9,248\n",
       "│    │    └─FullyConnectedLayer: 3-15         [1, 32]                   (16,416)\n",
       "│    └─SynthesisLayer: 2-18                   [1, 3, 1024, 1024]        99\n",
       "│    │    └─FullyConnectedLayer: 3-16         [1, 32]                   (16,416)\n",
       "===============================================================================================\n",
       "Total params: 22,313,167\n",
       "Trainable params: 0\n",
       "Non-trainable params: 22,313,167\n",
       "Total mult-adds (M): 3.06\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 12.26\n",
       "Estimated Total Size (MB): 12.31\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = {\n",
    "            \"z\": z,\n",
    "            \"c\": label,\n",
    "            \"truncation_psi\": 0.5,\n",
    "        }\n",
    "summary(G_b, input_data=inp, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (synthesis): SynthesisNetwork(\n",
       "    w_dim=512, num_ws=16,\n",
       "    img_resolution=1024, img_channels=3,\n",
       "    num_layers=14, num_critical=2,\n",
       "    margin_size=10, num_fp16_res=4\n",
       "    (input): SynthesisInput(\n",
       "      w_dim=512, channels=512, size=[36, 36],\n",
       "      sampling_rate=16, bandwidth=2\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=4, activation=linear)\n",
       "    )\n",
       "    (L0_36_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=False,\n",
       "      in_sampling_rate=16, out_sampling_rate=16,\n",
       "      in_cutoff=2, out_cutoff=2,\n",
       "      in_half_width=6, out_half_width=6,\n",
       "      in_size=[36, 36], out_size=[36, 36],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L1_36_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=False,\n",
       "      in_sampling_rate=16, out_sampling_rate=16,\n",
       "      in_cutoff=2, out_cutoff=3.1748,\n",
       "      in_half_width=6, out_half_width=4.8252,\n",
       "      in_size=[36, 36], out_size=[36, 36],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L2_52_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=False,\n",
       "      in_sampling_rate=16, out_sampling_rate=32,\n",
       "      in_cutoff=3.1748, out_cutoff=5.03968,\n",
       "      in_half_width=4.8252, out_half_width=10.9603,\n",
       "      in_size=[36, 36], out_size=[52, 52],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L3_52_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=False,\n",
       "      in_sampling_rate=32, out_sampling_rate=32,\n",
       "      in_cutoff=5.03968, out_cutoff=8,\n",
       "      in_half_width=10.9603, out_half_width=8,\n",
       "      in_size=[52, 52], out_size=[52, 52],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L4_84_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=False,\n",
       "      in_sampling_rate=32, out_sampling_rate=64,\n",
       "      in_cutoff=8, out_cutoff=12.6992,\n",
       "      in_half_width=8, out_half_width=19.3008,\n",
       "      in_size=[52, 52], out_size=[84, 84],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L5_148_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=64, out_sampling_rate=128,\n",
       "      in_cutoff=12.6992, out_cutoff=20.1587,\n",
       "      in_half_width=19.3008, out_half_width=43.8413,\n",
       "      in_size=[84, 84], out_size=[148, 148],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L6_148_512): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=128, out_sampling_rate=128,\n",
       "      in_cutoff=20.1587, out_cutoff=32,\n",
       "      in_half_width=43.8413, out_half_width=32,\n",
       "      in_size=[148, 148], out_size=[148, 148],\n",
       "      in_channels=512, out_channels=512\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L7_276_323): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=128, out_sampling_rate=256,\n",
       "      in_cutoff=32, out_cutoff=50.7968,\n",
       "      in_half_width=32, out_half_width=77.2032,\n",
       "      in_size=[148, 148], out_size=[276, 276],\n",
       "      in_channels=512, out_channels=323\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
       "    )\n",
       "    (L8_276_203): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=256, out_sampling_rate=256,\n",
       "      in_cutoff=50.7968, out_cutoff=80.6349,\n",
       "      in_half_width=77.2032, out_half_width=47.3651,\n",
       "      in_size=[276, 276], out_size=[276, 276],\n",
       "      in_channels=323, out_channels=203\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=323, activation=linear)\n",
       "    )\n",
       "    (L9_532_128): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=256, out_sampling_rate=512,\n",
       "      in_cutoff=80.6349, out_cutoff=128,\n",
       "      in_half_width=47.3651, out_half_width=128,\n",
       "      in_size=[276, 276], out_size=[532, 532],\n",
       "      in_channels=203, out_channels=128\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=203, activation=linear)\n",
       "    )\n",
       "    (L10_1044_81): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=512, out_sampling_rate=1024,\n",
       "      in_cutoff=128, out_cutoff=203.187,\n",
       "      in_half_width=128, out_half_width=308.813,\n",
       "      in_size=[532, 532], out_size=[1044, 1044],\n",
       "      in_channels=128, out_channels=81\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
       "    )\n",
       "    (L11_1044_51): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=False, use_fp16=True,\n",
       "      in_sampling_rate=1024, out_sampling_rate=1024,\n",
       "      in_cutoff=203.187, out_cutoff=322.54,\n",
       "      in_half_width=308.813, out_half_width=189.46,\n",
       "      in_size=[1044, 1044], out_size=[1044, 1044],\n",
       "      in_channels=81, out_channels=51\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=81, activation=linear)\n",
       "    )\n",
       "    (L12_1044_32): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=True, use_fp16=True,\n",
       "      in_sampling_rate=1024, out_sampling_rate=1024,\n",
       "      in_cutoff=322.54, out_cutoff=512,\n",
       "      in_half_width=189.46, out_half_width=118.346,\n",
       "      in_size=[1044, 1044], out_size=[1044, 1044],\n",
       "      in_channels=51, out_channels=32\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=51, activation=linear)\n",
       "    )\n",
       "    (L13_1024_32): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=False,\n",
       "      is_critically_sampled=True, use_fp16=True,\n",
       "      in_sampling_rate=1024, out_sampling_rate=1024,\n",
       "      in_cutoff=512, out_cutoff=512,\n",
       "      in_half_width=118.346, out_half_width=118.346,\n",
       "      in_size=[1044, 1044], out_size=[1024, 1024],\n",
       "      in_channels=32, out_channels=32\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=32, activation=linear)\n",
       "    )\n",
       "    (L14_1024_3): SynthesisLayer(\n",
       "      w_dim=512, is_torgb=True,\n",
       "      is_critically_sampled=True, use_fp16=True,\n",
       "      in_sampling_rate=1024, out_sampling_rate=1024,\n",
       "      in_cutoff=512, out_cutoff=512,\n",
       "      in_half_width=118.346, out_half_width=118.346,\n",
       "      in_size=[1024, 1024], out_size=[1024, 1024],\n",
       "      in_channels=32, out_channels=3\n",
       "      (affine): FullyConnectedLayer(in_features=512, out_features=32, activation=linear)\n",
       "    )\n",
       "  )\n",
       "  (mapping): MappingNetwork(\n",
       "    z_dim=512, c_dim=0, w_dim=512, num_ws=16\n",
       "    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import PIL\n",
    "folder = \"out2\"\n",
    "def load_and_make_grid(folder):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder), key=lambda x: int(x.split(\".\")[0].split(\"seed\")[1])):\n",
    "        img = PIL.Image.open(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(torchvision.transforms.ToTensor()(img))\n",
    "    return torchvision.utils.make_grid(images, nrow=4)\n",
    "grid = load_and_make_grid(folder)\n",
    "torchvision.utils.save_image(grid, \"grid_sg3_noema.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anyres-gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b92608fad6a80d8be030d615afeb1226eb9f6a82e69c4a77b80f1b1464b1659"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
